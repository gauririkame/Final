{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDB dataset\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)\n",
    "\n",
    "# Pad sequences to ensure all reviews are the same length\n",
    "X_train = pad_sequences(X_train, maxlen=200)\n",
    "X_test = pad_sequences(X_test, maxlen=200)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(input_dim=10000, output_dim=128))  # Removed input_length\n",
    "    model.add(layers.LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "def decode_review(encoded_review):\n",
    "    reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
    "    decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in encoded_review])\n",
    "    return decoded_review\n",
    "\n",
    "# Decode the first 3 reviews in the test set\n",
    "sample_reviews = [decode_review(X_test[i]) for i in range(3)]\n",
    "\n",
    "# Preprocess reviews\n",
    "def preprocess_reviews(reviews):\n",
    "    sequences = imdb.get_word_index()\n",
    "    indices = [[sequences.get(word, 0) for word in review.split()] for review in reviews]\n",
    "    return pad_sequences(indices, maxlen=200)\n",
    "\n",
    "preprocessed_reviews = preprocess_reviews(sample_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(preprocessed_reviews)\n",
    "\n",
    "# Output the predictions\n",
    "for review, prediction in zip(sample_reviews, predictions):\n",
    "    sentiment = 'Positive' if prediction > 0.5 else 'Negative'\n",
    "    print(f'Review: \"{review}\"\\nPredicted Sentiment: {sentiment}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
